{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import multiprocessing as mp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse, spatial\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/data_set_0926/'\n",
    "FEAT_PATH = './features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 100 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "invite_info = pd.read_csv(os.path.join(DATA_PATH, 'invite_info_0926.txt'), names=['qid', 'author_id', 'itime', 'label'], sep='\\t')\n",
    "invite_info_evaluate = pd.read_csv(os.path.join(DATA_PATH, 'invite_info_evaluate_2_0926.txt'), names=['qid', 'author_id', 'itime'], sep='\\t')\n",
    "\n",
    "answer_info = pd.read_csv(os.path.join(DATA_PATH, 'answer_info_0926.txt'), names=['aid', 'qid', 'author_id', 'atime', 'content_sw', 'content_w', 'excellent', 'recommend', 'round_table', 'figure', 'video', 'num_word', 'num_like', 'num_unlike', 'num_comment','num_favor', 'num_thank', 'num_report', 'num_nohelp', 'num_oppose'], sep='\\t')\n",
    "del answer_info['content_sw'], answer_info['content_w']\n",
    "\n",
    "data = pd.concat([invite_info, invite_info_evaluate]).reset_index(drop=True)\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4513735it [11:00, 6835.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 777 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "tmp = data['itime'].apply(lambda x : x.split('-'))\n",
    "data['invite_hour'] = tmp.apply(lambda x : int(x[1::1][0][1:]))\n",
    "data['invite_day'] = tmp.apply(lambda x : int(x[::2][0][1:]))\n",
    "\n",
    "tmp = answer_info['atime'].apply(lambda x : x.split('-'))\n",
    "answer_info['answer_hour'] = tmp.apply(lambda x : int(x[1::1][0][1:]))\n",
    "answer_info['answer_day'] = tmp.apply(lambda x : int(x[::2][0][1:]))\n",
    "\n",
    "answer_info['answer_day'] = answer_info['answer_day'].astype(int)\n",
    "answer_info['answer_hour'] = answer_info['answer_hour'].astype(int)\n",
    "answer_info['author_time'] = answer_info['author_id'] + '_' + (answer_info['answer_day'] * 24 + answer_info['answer_hour']).astype(int).astype(str)\n",
    "answer_info.sort_values(by=['author_id', 'author_time'],inplace=True)\n",
    "answer_info = answer_info[['qid', 'author_id', 'author_time']].reset_index(drop=True)\n",
    "\n",
    "prev_ans_ques = []\n",
    "ques = []\n",
    "last = None\n",
    "for _, row in tqdm(answer_info.iterrows()):\n",
    "    a = row['author_id']\n",
    "    q = row['qid']\n",
    "    if last is None or last != a:\n",
    "        ques = [q]\n",
    "    else:\n",
    "        ques.append(q)\n",
    "    prev_ans_ques.append(list(ques))\n",
    "    last = a\n",
    "\n",
    "answer_info['prev_ans_ques'] = prev_ans_ques\n",
    "del answer_info['qid'], answer_info['author_id']\n",
    "answer_info.drop_duplicates(subset='author_time', keep='last', inplace=True)\n",
    "\n",
    "inv_last_answer_time = pd.read_pickle(os.path.join(FEAT_PATH, 'inv_last_answer_time.pkl')).reset_index(drop=True)\n",
    "tmp = inv_last_answer_time.merge(answer_info, 'left', 'author_time')\n",
    "\n",
    "tmp[['prev_ans_ques']].to_pickle(os.path.join(FEAT_PATH, 'prev_ans_ques.pkl'))\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11690404\n",
      "(1829900, 1762829)\n",
      "(1829900, 64)\n",
      "Used time: 373 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "question_info = pd.read_csv(os.path.join(os.path.join(DATA_PATH, 'question_info_0926.txt')),\n",
    "                          names=['question_id', 'qtime', 'title_sw', 'title_w', 'desc_sw', 'desc_w', 'topic'], sep='\\t')\n",
    "\n",
    "question_id_map = dict((question_info['question_id'][i], i) for i in range(len(question_info)))\n",
    "\n",
    "with open(os.path.join(FEAT_PATH, 'question_id_map.pkl'), 'wb') as file:\n",
    "    pickle.dump(question_id_map, file)\n",
    "    \n",
    "question_info['title_w_series'] = question_info['title_w'].apply(lambda x: [int(num[1:]) for num in x.split(',')])\n",
    "\n",
    "word = pd.read_table(os.path.join(os.path.join(DATA_PATH, 'word_vectors_64d.txt'), header=None)\n",
    "word.columns = ['id','embed']\n",
    "word['embed'] = word['embed'].apply(lambda x: [float(num) for num in x.split(' ')])\n",
    "word['id'] = word['id'].apply(lambda x: int(x[1:]))\n",
    "\n",
    "word_arr = np.array([v for v in word['embed'].values])\n",
    "vocabulary = dict((str(word['id'][i]), i) for i in range(len(word)))\n",
    "title = question_info['title_w_series'].astype(str)\n",
    "cnt_vct = CountVectorizer(token_pattern='\\\\d+', binary=True, lowercase=False, vocabulary=vocabulary)\n",
    "cnt_vct.fit(title)\n",
    "\n",
    "A = cnt_vct.transform(title)\n",
    "print(A.sum())\n",
    "print(A.shape)\n",
    "\n",
    "B = word_arr.astype(float)\n",
    "B = sparse.csr_matrix(B)\n",
    "C = A.dot(B)\n",
    "print(C.shape)\n",
    "C = C.toarray()\n",
    "title_len = question_info['title_w_series'].apply(len).values.reshape((-1, 1))\n",
    "C /= title_len\n",
    "\n",
    "np.save(os.path.join(FEAT_PATH, 'title_embed.npy', C))\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load question_id_map\n",
      "load title_embed\n",
      "start...\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2231/10630880 [00:00<16:03, 11031.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10630880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10630880/10630880 [14:54<00:00, 11879.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 1302 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "def cos_sim(a, b):\n",
    "    return 1 - spatial.distance.cosine(a, b)\n",
    "\n",
    "prev_ans_ques = pd.read_pickle(os.path.join(FEAT_PATH, 'prev_ans_ques.pkl')).reset_index(drop=True)\n",
    "\n",
    "ques_pair = data[['qid']]\n",
    "ques_pair = pd.concat([ques_pair, prev_ans_ques], axis=1)\n",
    "\n",
    "print('load question_id_map')\n",
    "with open(os.path.join(FEAT_PATH, 'question_id_map.pkl'), 'rb') as file:\n",
    "    question_id_map = pickle.load(file)\n",
    "\n",
    "print('load title_embed')\n",
    "title_embed  = np.load(os.path.join(FEAT_PATH, 'title_embed.npy'))\n",
    "\n",
    "print('start...')\n",
    "\n",
    "def split_df(df, n):\n",
    "    chunk_size = int(np.ceil(len(df) / n))\n",
    "    return [df[i*chunk_size:(i+1)*chunk_size] for i in range(n)]\n",
    "\n",
    "def process(df):\n",
    "    prev_ans_ques_sim = []\n",
    "    for q1, qs in (df.values):\n",
    "        ques_sim = []\n",
    "        qv1 = title_embed[question_id_map[q1]]\n",
    "        # print(qv1)\n",
    "        if type(qs) == list:\n",
    "            for q2 in qs:\n",
    "                qv2 = title_embed[question_id_map[q2]]\n",
    "                # print(qv2)\n",
    "                sim = cos_sim(qv1, qv2)\n",
    "                ques_sim.append(sim)\n",
    "        else:\n",
    "            ques_sim = [0]\n",
    "        prev_ans_ques_sim.append(ques_sim)\n",
    "    # print(len(prev_ans_ques_sim))\n",
    "    return prev_ans_ques_sim\n",
    "\n",
    "chunk_list = split_df(ques_pair, 100)\n",
    "print(len(chunk_list))\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    ret = pool.map(process, chunk_list)\n",
    "\n",
    "prev_ans_ques_sim = []\n",
    "for r in ret:\n",
    "    prev_ans_ques_sim += r\n",
    "            \n",
    "print(len(prev_ans_ques_sim))\n",
    "for r in ret:\n",
    "    del r\n",
    "del ret\n",
    "\n",
    "prev_ans_ques_title_sim = pd.DataFrame()\n",
    "min_ = []\n",
    "max_ = []\n",
    "mean_ = []\n",
    "std_ = []\n",
    "for s in tqdm(prev_ans_ques_sim):\n",
    "    min_.append(np.min(s))\n",
    "    max_.append(np.max(s))\n",
    "    mean_.append(np.mean(s))\n",
    "    std_.append(np.std(s))\n",
    "\n",
    "prev_ans_ques_title_sim['prev_ans_ques_title_sim_min'] = min_\n",
    "prev_ans_ques_title_sim['prev_ans_ques_title_sim_max'] = max_\n",
    "prev_ans_ques_title_sim['prev_ans_ques_title_sim_mean'] = mean_\n",
    "prev_ans_ques_title_sim['prev_ans_ques_title_sim_std'] = std_\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Saved, shape: (10630880, 4)\n"
     ]
    }
   ],
   "source": [
    "prev_ans_ques_title_sim.to_pickle(os.path.join(FEAT_PATH, 'prev_ans_ques_title_sim.pickle'))\n",
    "print(\"Feature Saved, shape:\",prev_ans_ques_title_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
