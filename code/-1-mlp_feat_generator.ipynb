{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./features/'):\n",
    "    os.mkdir('./features/')\n",
    "if not os.path.exists('./out/'):\n",
    "    os.mkdir('./out/')\n",
    "if not os.path.exists('./weights/'):\n",
    "    os.mkdir('./weights/')\n",
    "    \n",
    "DATA_PATH = '../data/data_set_0926/'\n",
    "FEAT_PATH = './features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "invite_info = pd.read_table(os.path.join(DATA_PATH, 'invite_info_0926.txt'), header=None)\n",
    "invite_info.columns = ['问题ID','用户ID','邀请创建时间','邀请是否被回答']\n",
    "\n",
    "invite_info_evaluate_A = pd.read_table(os.path.join(DATA_PATH, 'invite_info_evaluate_1_0926.txt'), header=None)\n",
    "invite_info_evaluate_A.columns =  ['问题ID','用户ID','邀请创建时间']\n",
    "\n",
    "invite_info_evaluate_B = pd.read_table(os.path.join(DATA_PATH, 'invite_info_evaluate_2_0926.txt'), header=None)\n",
    "invite_info_evaluate_B.columns =  ['问题ID','用户ID','邀请创建时间']\n",
    "\n",
    "question_info = pd.read_table(os.path.join(DATA_PATH, 'question_info_0926.txt', header=None)\n",
    "question_info.columns = ['问题ID',  '问题创建时间' , '问题标题的单字编码序列' , '问题标题的切词编码序列' , '问题描述的单字编码序列',  '问题描述的词编码序列' , '问题绑定的话题ID']\n",
    "                              \n",
    "member_info = pd.read_table(os.path.join(DATA_PATH, 'member_info_0926.txt'), header=None)\n",
    "member_info.columns = ['用户ID','性别','创作关键词的编码序列','创作数量等级','创作热度等级','注册类型','注册平台','访问频率','用户二分类特征A','用户二分类特征B','用户二分类特征C','用户二分类特征D','用户二分类特征E','用户分类特征A','用户分类特征B','用户分类特征C','用户分类特征D','用户分类特征E','用户的盐值分数','用户关注的话题','用户感兴趣的话题']\n",
    "\n",
    "tmp = member_info['用户感兴趣的话题'].apply(lambda x: re.split('[,:]',x))\n",
    "member_info['用户感兴趣的话题_T'] = tmp.apply(lambda x : ','.join(x[::2]))\n",
    "member_info['用户感兴趣的话题_score'] = tmp.apply(lambda x : ','.join(x[1::2]))\n",
    "                              \n",
    "oversample = False\n",
    "\n",
    "if oversample:\n",
    "    data = pd.concat([invite_info, invite_info_evaluate_B, invite_info_evaluate_A], axis=0)\n",
    "else:\n",
    "    data = pd.concat([invite_info, invite_info_evaluate_B], axis=0)\n",
    "    \n",
    "data = data.merge(member_info, on='用户ID', how='left').merge(question_info, on='问题ID', how='left')                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "single_word_vectors = pd.read_table(os.path.join(DATA_PATH, 'single_word_vectors_64d.txt'), header=None)\n",
    "single_word_vectors.columns = ['单字编码序号','SW']\n",
    "tmp = single_word_vectors.SW.apply(lambda x: x.split(' '))\n",
    "tmp = pd.DataFrame(list(tmp), columns=['SW_{}'.format(i) for i in range(1,65)]) \n",
    "del single_word_vectors['SW']\n",
    "single_word_vectors = pd.concat([single_word_vectors, tmp], axis=1)\n",
    "\n",
    "word_vectors = pd.read_table(os.path.join(DATA_PATH, 'word_vectors_64d.txt'), header=None)\n",
    "word_vectors.columns = ['词编码序号','W']\n",
    "tmp = word_vectors.W.apply(lambda x: x.split(' '))\n",
    "tmp = pd.DataFrame(list(tmp), columns=['W_{}'.format(i) for i in range(1,65)]) \n",
    "del word_vectors['W']\n",
    "word_vectors = pd.concat([word_vectors, tmp], axis=1)\n",
    "\n",
    "topic_vectors = pd.read_table(os.path.join(DATA_PATH, 'topic_vectors_64d.txt'), header=None)\n",
    "topic_vectors.columns = ['话题ID编码序号','Topic']\n",
    "tmp = topic_vectors.Topic.apply(lambda x: x.split(' '))\n",
    "tmp = pd.DataFrame(list(tmp), columns=['T_{}'.format(i) for i in range(1,65)]) \n",
    "del topic_vectors['Topic']\n",
    "topic_vectors = pd.concat([topic_vectors, tmp], axis=1)\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829900, 64)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "vocabulary = dict((single_word_vectors['单字编码序号'][i], i) for i in range(len(single_word_vectors)))\n",
    "\n",
    "cnt_vct = CountVectorizer(token_pattern='\\\\w+\\\\d+', binary=True, lowercase=False, vocabulary=vocabulary)\n",
    "cnt_vct.fit(question_info['问题标题的单字编码序列'])\n",
    "\n",
    "A = cnt_vct.transform(question_info['问题标题的单字编码序列'])\n",
    "\n",
    "B = single_word_vectors.values[:, 1:].astype(float)\n",
    "B = sparse.csr_matrix(B)\n",
    "\n",
    "C = A.dot(B)\n",
    "print(C.shape)\n",
    "\n",
    "tmp = pd.DataFrame(C.toarray())\n",
    "tmp.columns = ['SW_w2v_sum_{}'.format(i) for i in range(1,65)]\n",
    "tmp['问题ID'] = question_info['问题ID']\n",
    "\n",
    "tmp.to_hdf(os.path.join(FEAT_PATH, 'ques_topic_SW_sum_64.h5'), key='data')\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829900, 64)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "vocabulary = dict((single_word_vectors['单字编码序号'][i], i) for i in range(len(single_word_vectors)))\n",
    "\n",
    "cnt_vct = CountVectorizer(token_pattern='\\\\w+\\\\d+', binary=True, lowercase=False, vocabulary=vocabulary)\n",
    "cnt_vct.fit(question_info['问题描述的单字编码序列'])\n",
    "\n",
    "A = cnt_vct.transform(question_info['问题描述的单字编码序列'])\n",
    "\n",
    "B = single_word_vectors.values[:, 1:].astype(float)\n",
    "B = sparse.csr_matrix(B)\n",
    "\n",
    "C = A.dot(B)\n",
    "print(C.shape)\n",
    "\n",
    "tmp = pd.DataFrame(C.toarray())\n",
    "tmp.columns = ['ques_describe_SW_w2v_sum_{}'.format(i) for i in range(1,65)]\n",
    "tmp['问题ID'] = question_info['问题ID']\n",
    "\n",
    "tmp.to_hdf(os.path.join(FEAT_PATH, 'ques_describe_SW_sum_64.h5'), key='data')\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829900, 64)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "vocabulary = dict((word_vectors['词编码序号'][i], i) for i in range(len(word_vectors)))\n",
    "\n",
    "cnt_vct = CountVectorizer(token_pattern='\\\\w+\\\\d+', binary=True, lowercase=False, vocabulary=vocabulary)\n",
    "cnt_vct.fit(question_info['问题标题的切词编码序列'])\n",
    "\n",
    "A = cnt_vct.transform(question_info['问题标题的切词编码序列'])\n",
    "\n",
    "B = word_vectors.values[:, 1:].astype(float)\n",
    "B = sparse.csr_matrix(B)\n",
    "\n",
    "C = A.dot(B)\n",
    "print(C.shape)\n",
    "\n",
    "tmp = pd.DataFrame(C.toarray())\n",
    "tmp.columns = ['ques_topic_W_w2v_sum_{}'.format(i) for i in range(1,65)]\n",
    "tmp['问题ID'] = question_info['问题ID']\n",
    "\n",
    "tmp.to_hdf(os.path.join(FEAT_PATH, 'ques_topic_W_sum_64.h5') ,key='data')\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829900, 64)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "vocabulary = dict((word_vectors['词编码序号'][i], i) for i in range(len(word_vectors)))\n",
    "\n",
    "cnt_vct = CountVectorizer(token_pattern='\\\\w+\\\\d+', binary=True, lowercase=False, vocabulary=vocabulary)\n",
    "cnt_vct.fit(question_info['问题描述的词编码序列'])\n",
    "\n",
    "A = cnt_vct.transform(question_info['问题描述的词编码序列'])\n",
    "\n",
    "B = word_vectors.values[:, 1:].astype(float)\n",
    "B = sparse.csr_matrix(B)\n",
    "\n",
    "C = A.dot(B)\n",
    "print(C.shape)\n",
    "\n",
    "tmp = pd.DataFrame(C.toarray())\n",
    "tmp.columns = ['ques_describe_W_w2v_sum_{}'.format(i) for i in range(1,65)]\n",
    "tmp['问题ID'] = question_info['问题ID']\n",
    "\n",
    "tmp.to_hdf(os.path.join(FEAT_PATH, 'ques_describe_W_sum_64.h5'), key='data')\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1931654, 64)\n"
     ]
    }
   ],
   "source": [
    "vocabulary = dict((topic_vectors['话题ID编码序号'][i], i) for i in range(len(topic_vectors)))\n",
    "\n",
    "cnt_vct = CountVectorizer(token_pattern='\\\\w+\\\\d+', binary=True, lowercase=False, vocabulary=vocabulary)\n",
    "cnt_vct.fit(member_info['用户关注的话题'])\n",
    "\n",
    "A = cnt_vct.transform(member_info['用户关注的话题'])\n",
    "\n",
    "B = topic_vectors.values[:, 1:].astype(float)\n",
    "B = sparse.csr_matrix(B)\n",
    "\n",
    "C = A.dot(B)\n",
    "print(C.shape)\n",
    "\n",
    "tmp = pd.DataFrame(C.toarray())\n",
    "tmp.columns = ['用户关注的话题_w2v_sum_{}'.format(i) for i in range(1,65)]\n",
    "tmp['用户ID'] = member_info['用户ID']\n",
    "\n",
    "tmp.to_hdf(os.path.join(FEAT_PATH, 'user_watched_topic_w2v_sum_64.h5'), key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1931654, 64)\n"
     ]
    }
   ],
   "source": [
    "vocabulary = dict((topic_vectors['话题ID编码序号'][i], i) for i in range(len(topic_vectors)))\n",
    "\n",
    "cnt_vct = CountVectorizer(token_pattern='\\\\w+\\\\d+', binary=True, lowercase=False, vocabulary=vocabulary)\n",
    "cnt_vct.fit(member_info['用户感兴趣的话题_T'])\n",
    "\n",
    "A = cnt_vct.transform(member_info['用户感兴趣的话题_T'])\n",
    "\n",
    "B = topic_vectors.values[:, 1:].astype(float)\n",
    "B = sparse.csr_matrix(B)\n",
    "\n",
    "C = A.dot(B)\n",
    "print(C.shape)\n",
    "\n",
    "tmp = pd.DataFrame(C.toarray())\n",
    "tmp.columns = ['用户感兴趣的话题_w2v_sum_{}'.format(i) for i in range(1,65)]\n",
    "tmp['用户ID'] = member_info['用户ID']\n",
    "\n",
    "tmp.to_hdf(os.path.join(FEAT_PATH, 'user_fav_topic_w2v_sum_64.h5'), key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829900, 64)\n"
     ]
    }
   ],
   "source": [
    "vocabulary = dict((topic_vectors['话题ID编码序号'][i], i) for i in range(len(topic_vectors)))\n",
    "\n",
    "cnt_vct = CountVectorizer(token_pattern='\\\\w+\\\\d+', binary=True, lowercase=False, vocabulary=vocabulary)\n",
    "cnt_vct.fit(question_info['问题绑定的话题ID'])\n",
    "\n",
    "A = cnt_vct.transform(question_info['问题绑定的话题ID'])\n",
    "\n",
    "B = topic_vectors.values[:, 1:].astype(float)\n",
    "B = sparse.csr_matrix(B)\n",
    "\n",
    "C = A.dot(B)\n",
    "print(C.shape)\n",
    "\n",
    "tmp = pd.DataFrame(C.toarray())\n",
    "tmp.columns = ['问题绑定的话题ID_w2v_sum_{}'.format(i) for i in range(1,65)]\n",
    "tmp['问题ID'] = question_info['问题ID']\n",
    "\n",
    "tmp.to_hdf(os.path.join(FEAT_PATH, 'ques_attach_topic_w2v_sum_64.h5'), key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
