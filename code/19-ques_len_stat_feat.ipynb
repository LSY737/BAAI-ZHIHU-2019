{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 64 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()\n",
    "import Levenshtein\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/data_set_0926/'\n",
    "FEAT_PATH = './features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 116 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "invite_info = pd.read_table(os.path.join(DATA_PATH, 'invite_info_0926.txt'), header=None)\n",
    "invite_info.columns = ['问题ID','用户ID','邀请创建时间','邀请是否被回答']\n",
    "\n",
    "invite_info_evaluate_A = pd.read_table(os.path.join(DATA_PATH, 'invite_info_evaluate_1_0926.txt'), header=None)\n",
    "invite_info_evaluate_A.columns =  ['问题ID','用户ID','邀请创建时间']\n",
    "\n",
    "invite_info_evaluate_B = pd.read_table(os.path.join(DATA_PATH, 'invite_info_evaluate_2_0926.txt'), header=None)\n",
    "invite_info_evaluate_B.columns =  ['问题ID','用户ID','邀请创建时间']\n",
    "\n",
    "question_info = pd.read_table(os.path.join(DATA_PATH, 'question_info_0926.txt'), header=None)\n",
    "question_info.columns = ['问题ID',  '问题创建时间' , '问题标题的单字编码序列' , '问题标题的切词编码序列' , '问题描述的单字编码序列',  '问题描述的词编码序列' , '问题绑定的话题ID']\n",
    "\n",
    "member_info = pd.read_table(os.path.join(DATA_PATH, 'member_info_0926.txt'), header=None)\n",
    "member_info.columns = ['用户ID','性别','创作关键词的编码序列','创作数量等级','创作热度等级','注册类型','注册平台','访问频率','用户二分类特征A','用户二分类特征B','用户二分类特征C','用户二分类特征D','用户二分类特征E','用户分类特征A','用户分类特征B','用户分类特征C','用户分类特征D','用户分类特征E','用户的盐值分数','用户关注的话题','用户感兴趣的话题']\n",
    "\n",
    "oversample = True\n",
    "\n",
    "if oversample:\n",
    "    data = pd.concat([invite_info, invite_info_evaluate_B, invite_info_evaluate_A], axis=0)\n",
    "else:\n",
    "    data = pd.concat([invite_info, invite_info_evaluate_B], axis=0)\n",
    "    \n",
    "data = data.merge(member_info, on='用户ID', how='left').merge(question_info, on='问题ID', how='left')\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 91 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "feature = pd.DataFrame()\n",
    "\n",
    "feature['问题标题_len'] = data['问题标题的单字编码序列'].apply(lambda x:len(x.split(',')))\n",
    "feature['问题描述_len'] = data['问题描述的单字编码序列'].apply(lambda x:len(x.split(',')))\n",
    "feature['问题描述_len-问题标题_len'] = feature['问题描述_len'] - feature['问题标题_len']\n",
    "\n",
    "feature['问题标题_W_len'] = data['问题标题的切词编码序列'].apply(lambda x:len(x.split(',')))\n",
    "feature['问题描述_W_len'] = data['问题描述的词编码序列'].apply(lambda x:len(x.split(',')))\n",
    "feature['问题描述_len-问题标题_len_W'] = feature['问题描述_W_len'] - feature['问题标题_W_len']\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 377 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "def get_union_data(row):\n",
    "    title_list = row['问题标题的单字编码序列'].split(',')\n",
    "    query_list = row['问题描述的单字编码序列'].split(',')\n",
    "    return len(list(set(title_list).intersection(set(query_list))))\n",
    "\n",
    "feature['问题标题和描述的交集个数'] = data.parallel_apply(lambda row:get_union_data(row), axis=1)\n",
    "\n",
    "def get_union_data(row):\n",
    "    title_list = row['问题标题的切词编码序列'].split(',')\n",
    "    query_list = row['问题描述的词编码序列'].split(',')\n",
    "    return len(list(set(title_list).intersection(set(query_list))))\n",
    "\n",
    "feature['问题标题和描述的交集个数_W'] = data.parallel_apply(lambda row:get_union_data(row), axis=1)\n",
    "\n",
    "feature['问题标题和描述的交集个数/问题标题_len'] = np.around(np.divide(feature['问题标题和描述的交集个数'], feature['问题标题_len']), 8)\n",
    "feature['问题标题和描述的交集个数/问题描述_len'] = np.around(np.divide(feature['问题标题和描述的交集个数'], feature['问题描述_len']), 8)\n",
    "feature['问题标题和描述的交集个数_W/问题标题_len'] = np.around(np.divide(feature['问题标题和描述的交集个数_W'], feature['问题标题_len']), 8)\n",
    "feature['问题标题和描述的交集个数_W/问题描述_len'] = np.around(np.divide(feature['问题标题和描述的交集个数_W'], feature['问题描述_len']), 8)\n",
    "\n",
    "feature['编辑距离'] = data.parallel_apply(lambda row:Levenshtein.distance(row['问题标题的单字编码序列'], row['问题描述的单字编码序列']), axis=1)\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 508 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "def same_1(row):\n",
    "    title_list = row['问题标题的单字编码序列'].split(',')\n",
    "    query_list = row['问题描述的单字编码序列'].split(',')\n",
    "    if title_list[0] ==  query_list[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def same_2(row):\n",
    "    title_list = row['问题标题的单字编码序列'].split(',')\n",
    "    query_list = row['问题描述的单字编码序列'].split(',')\n",
    "    if ' '.join(title_list[:2]) ==  ' '.join(query_list[:2]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def same_3(row):\n",
    "    title_list = row['问题标题的单字编码序列'].split(',')\n",
    "    query_list = row['问题描述的单字编码序列'].split(',')\n",
    "    if ' '.join(title_list[:3]) ==  ' '.join(query_list[:3]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "feature['前一个词语是否相同'] = data.parallel_apply(lambda row:same_1(row), axis=1)\n",
    "feature['前两个词语是否相同'] = data.parallel_apply(lambda row:same_2(row), axis=1)\n",
    "feature['前三个词语是否相同'] = data.parallel_apply(lambda row:same_3(row), axis=1)\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 340 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "def same_1(row):\n",
    "    title_list = row['问题标题的切词编码序列'].split(',')\n",
    "    query_list = row['问题描述的词编码序列'].split(',')\n",
    "    if title_list[0] ==  query_list[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def same_2(row):\n",
    "    title_list = row['问题标题的切词编码序列'].split(',')\n",
    "    query_list = row['问题描述的词编码序列'].split(',')\n",
    "    if ' '.join(title_list[:2]) ==  ' '.join(query_list[:2]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def same_3(row):\n",
    "    title_list = row['问题标题的切词编码序列'].split(',')\n",
    "    query_list = row['问题描述的词编码序列'].split(',')\n",
    "    if ' '.join(title_list[:3]) ==  ' '.join(query_list[:3]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "feature['前一个词语是否相同_W'] = data.parallel_apply(lambda row:same_1(row), axis=1)\n",
    "feature['前两个词语是否相同_W'] = data.parallel_apply(lambda row:same_2(row), axis=1)\n",
    "feature['前三个词语是否相同_W'] = data.parallel_apply(lambda row:same_3(row), axis=1)\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 348 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "def pos_1(row):\n",
    "    title_list = row['问题标题的单字编码序列'].split(',')\n",
    "    query_list = row['问题描述的单字编码序列'].split(',')\n",
    "    value = -1\n",
    "    try:\n",
    "        value = title_list.index(query_list[0])\n",
    "    except Exception:\n",
    "        value = -1\n",
    "    return value\n",
    "\n",
    "def pos_2(row):\n",
    "    title_list = row['问题标题的单字编码序列'].split(',')\n",
    "    query_list = row['问题描述的单字编码序列'].split(',')\n",
    "    if len(query_list) <=1 :\n",
    "        return -1\n",
    "    try:\n",
    "        value = title_list.index(query_list[1])\n",
    "    except Exception:\n",
    "        value = -1\n",
    "    return value\n",
    "\n",
    "def pos_3(row):\n",
    "    title_list = row['问题标题的单字编码序列'].split(',')\n",
    "    query_list = row['问题描述的单字编码序列'].split(',')\n",
    "    if len(query_list) <=2 :\n",
    "        return -1\n",
    "    try:\n",
    "        value = title_list.index(query_list[2])\n",
    "    except Exception:\n",
    "        value = -1\n",
    "    return value\n",
    "\n",
    "feature['第一个词语在标题里面出现位置'] = data.parallel_apply(lambda row:pos_1(row), axis=1)\n",
    "feature['第二个词语在标题里面出现位置'] = data.parallel_apply(lambda row:pos_2(row), axis=1)\n",
    "feature['第三个词语在标题里面出现位置'] = data.parallel_apply(lambda row:pos_3(row), axis=1)\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 196 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "tmp = data['用户感兴趣的话题'].apply(lambda x: re.split('[,:]',x))\n",
    "\n",
    "tmp_T = tmp.apply(lambda x : x[::2])\n",
    "tmp_Prob = tmp.apply(lambda x : x[1::2])\n",
    "\n",
    "tmp_T = tmp_T.apply(lambda x : ','.join(x))\n",
    "tmp_Prob = tmp_Prob.apply(lambda x : ','.join(x))\n",
    "\n",
    "data['用户感兴趣的话题_T'] = tmp_T\n",
    "data['用户感兴趣的话题_score'] = tmp_Prob\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used time: 623 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "def pos_1(row):\n",
    "    title_list = row['问题绑定的话题ID'].split(',')\n",
    "    query_list = row['用户感兴趣的话题_T'].split(',')\n",
    "    value = -1\n",
    "    try:\n",
    "        value = title_list.index(query_list[0])\n",
    "    except Exception:\n",
    "        value = -1\n",
    "    return value\n",
    "\n",
    "def pos_2(row):\n",
    "    title_list = row['问题绑定的话题ID'].split(',')\n",
    "    query_list = row['用户感兴趣的话题_T'].split(',')\n",
    "    if len(query_list) <=1 :\n",
    "        return -1\n",
    "    try:\n",
    "        value = title_list.index(query_list[1])\n",
    "    except Exception:\n",
    "        value = -1\n",
    "    return value\n",
    "\n",
    "def pos_3(row):\n",
    "    title_list = row['问题绑定的话题ID'].split(',')\n",
    "    query_list = row['用户感兴趣的话题_T'].split(',')\n",
    "    if len(query_list) <=2 :\n",
    "        return -1\n",
    "    try:\n",
    "        value = title_list.index(query_list[2])\n",
    "    except Exception:\n",
    "        value = -1\n",
    "    return value\n",
    "\n",
    "feature['第一感兴趣在问题绑定话题里面出现位置'] = data.parallel_apply(lambda row:pos_1(row), axis=1)\n",
    "feature['第二感兴趣在问题绑定话题里面出现位置'] = data.parallel_apply(lambda row:pos_2(row), axis=1)\n",
    "feature['第三感兴趣在问题绑定话题里面出现位置'] = data.parallel_apply(lambda row:pos_3(row), axis=1)\n",
    "\n",
    "feature['问题话题编辑距离'] = data.parallel_apply(lambda row:Levenshtein.distance(row['问题绑定的话题ID'], row['用户感兴趣的话题_T']), axis=1)\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "feature['用户ID'] = data['用户ID']\n",
    "\n",
    "tmp = feature.groupby(['用户ID'])['问题标题_len'].mean().reset_index()\n",
    "tmp.columns = ['用户ID','问题标题_len_mean']\n",
    "feature = feature.merge(tmp, on='用户ID', how='left')\n",
    "\n",
    "tmp = feature.groupby(['用户ID'])['问题描述_len'].mean().reset_index()\n",
    "tmp.columns = ['用户ID','问题描述_len_mean']\n",
    "feature = feature.merge(tmp, on='用户ID', how='left')\n",
    "\n",
    "tmp = feature.groupby(['用户ID'])['问题标题_W_len'].mean().reset_index()\n",
    "tmp.columns = ['用户ID','问题标题_W_len_mean']\n",
    "feature = feature.merge(tmp, on='用户ID', how='left')\n",
    "\n",
    "tmp = feature.groupby(['用户ID'])['问题描述_W_len'].mean().reset_index()\n",
    "tmp.columns = ['用户ID','问题描述_W_len_mean']\n",
    "feature = feature.merge(tmp, on='用户ID', how='left')\n",
    "\n",
    "del feature['用户ID']\n",
    "feature = feature[:len(invite_info)+len(invite_info_evaluate_B)]\n",
    "\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.to_pickle(os.path.join(FEAT_PATH, 'ques_len_stat_feat.pkl'))\n",
    "print(\"Feature Saved, shape:\",feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
