{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost==0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./data/data_all.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: train shape (9489162, 211), test shape (1141718, 211)\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(data):\n",
    "    origin_feature   = ['用户二分类特征A', '用户二分类特征B', '用户二分类特征C','用户二分类特征D', '用户二分类特征E','用户的盐值分数']\n",
    "    lbl_enc_feat = ['性别_lbl_enc','访问频率_lbl_enc','用户分类特征A_lbl_enc', '用户分类特征B_lbl_enc', '用户分类特征C_lbl_enc', '用户分类特征D_lbl_enc','用户分类特征E_lbl_enc']\n",
    "    user_ques_svd    = ['问题绑定的话题ID_svd_{}'.format(i) for i in range(1,31)]\n",
    "    user_ques_watched_svd  = ['用户关注的话题_svd_{}'.format(i) for i in range(1,11)]\n",
    "    user_ques_fav_svd  = ['user_ques_fav_svd_{}'.format(i) for i in range(1,11)]\n",
    "    nn_stack = ['w2v_sum_nn']\n",
    "\n",
    "    test_feat = ['问题邀请用户_counts','用户被邀请问题_counts','用户的盐值分数_max',\n",
    "                 '用户的盐值分数_min','用户的盐值分数_std','用户的盐值分数_mean','invite_answer_gap','邀请问题创建时间_gap',\n",
    "                '用户关注的话题_len','用户感兴趣的话题_len','问题绑定的话题ID_len','prev_ans_ques_title_sim_min', 'prev_ans_ques_title_sim_max',\n",
    "           'prev_ans_ques_title_sim_mean', 'prev_ans_ques_title_sim_std']\n",
    "    \n",
    "    new_feat = ['用户ID_last_expo','用户ID_next_expo','问题ID_last_expo','问题ID_next_expo','问题创建时间_H','邀请创建时间_H']\n",
    "    \n",
    "    new_feat_II = ['用户_问题IDs_svd_{}'.format(i) for i in range(1,11)]+['问题_用户IDs_svd_{}'.format(i) for i in range(1,11)]+['lstm_enc_feat']+\\\n",
    "     ['邀请创建时间_mean','邀请创建时间_max','邀请创建时间_min','邀请创建时间_std','问题创建时间_mean','问题创建时间_max','问题创建时间_min',\n",
    "      '问题创建时间_std','用户ID曾经回答数','用户问题ID_count','用户问题话题相同个数','用户感兴趣问题话题相同个数']\n",
    "      \n",
    "    new_feat_III = ['问题_用户感兴趣_topic_sim','问题_用户关注_topic_sim','用户关注_感兴趣_topic_sim']\n",
    "    \n",
    "    new_feat_IV = ['回答是否被标优_count', '回答是否被推荐_count' , '是否包含图片_count' ,\n",
    "                   '是否包含视频_count','回答字数_mean' ,'点赞数_mean', '取赞数_mean' ,'评论数_mean' ,\n",
    "                   '收藏数_mean', '感谢数_mean' ,'举报数_mean', '没有帮助数_mean' ,'反对数_mean']\n",
    "    \n",
    "    new_feat_V = ['回答字数_sum' ,'点赞数_sum', '取赞数_sum' ,'评论数_sum' ,'收藏数_sum', '感谢数_sum' ,\n",
    "                  '举报数_sum', '没有帮助数_sum' ,'反对数_sum']\n",
    "\n",
    "    new_feat_VI = ['问题标题_曾经回答_SW_sim','问题描述_曾经回答_SW_sim','问题标题_曾经回答_W_sim','问题描述_曾经回答_W_sim','times_mean',\n",
    "                   'times_max','times_min','times_std','Hs_mean','Hs_max','Hs_min','Hs_std']\n",
    "    \n",
    "    new_feat_VII = ['问题描述_曾经回答_Topic_sim','prev_topic_sims_min','prev_topic_sims_max','prev_topic_sims_mean','prev_topic_sims_std']\n",
    "    feat_I =['question_curr_expo','user_curr_expo']\n",
    "    feat_II = ['prev_ans_times_min_gap', 'prev_ans_times_mean_gap', 'qtime_std','qtime_mean', 'utime_std', 'utime_mean', 'iweek', 'qlast_itime_gap','qllast_itime_gap', 'qlllast_itime_gap', 'qnext_itime_gap','qnnext_itime_gap', 'qnnnext_itime_gap', 'ulast_itime_gap','ullast_itime_gap', 'ulllast_itime_gap', 'unext_itime_gap','unnext_itime_gap', 'unnnext_itime_gap']\n",
    "    new_feat_VIII = feat_I + feat_II \n",
    "    ques_len_stat_feat = ['问题标题_len', '问题描述_len', '问题描述_len-问题标题_len', '问题标题_W_len', '问题描述_W_len','问题描述_len-问题标题_len_W', '问题标题和描述的交集个数', '问题标题和描述的交集个数_W', '问题标题和描述的交集个数/问题标题_len', '问题标题和描述的交集个数/问题描述_len', '问题标题和描述的交集个数_W/问题标题_len', '问题标题和描述的交集个数_W/问题描述_len', '编辑距离',\n",
    "       '前一个词语是否相同', '前两个词语是否相同', '前三个词语是否相同', '前一个词语是否相同_W', '前两个词语是否相同_W','前三个词语是否相同_W','第一个词语在标题里面出现位置', '第二个词语在标题里面出现位置', '第三个词语在标题里面出现位置','第一感兴趣在问题绑定话题里面出现位置', '第二感兴趣在问题绑定话题里面出现位置', '第三感兴趣在问题绑定话题里面出现位置', '问题话题编辑距离',\n",
    "       '问题标题_len_mean', '问题描述_len_mean', '问题标题_W_len_mean', '问题描述_W_len_mean']\n",
    "    #******* Feature sum***********#\n",
    "    feature  =    origin_feature + lbl_enc_feat + user_ques_svd + user_ques_watched_svd + user_ques_fav_svd + nn_stack +\\\n",
    "                   test_feat + new_feat + new_feat_II + new_feat_III + new_feat_IV + new_feat_V + new_feat_VI+\\\n",
    "                  new_feat_VII + new_feat_VIII + ques_len_stat_feat\n",
    "    \n",
    "    #*********************************# \n",
    "    len_train = 9489162\n",
    "#     train = data[:len_train]\n",
    "#     test = data[len_train:]\n",
    "#     test_index = np.isnan(data['邀请是否被回答'])\n",
    "#     train_index = ~test_index\n",
    "    train_x = data[:len_train][feature] \n",
    "    train_y = data[:len_train]['邀请是否被回答']\n",
    "    test_x  = data[len_train:][feature]\n",
    "    train_x.columns = ['col_{}'.format(i) for i in range(211)]\n",
    "    test_x.columns = ['col_{}'.format(i) for i in range(211)]\n",
    "    return train_x, train_y, test_x,feature\n",
    "    \n",
    "train_x, train_y, test_x,feature = train_test_split(data)\n",
    "del data\n",
    "gc.collect()\n",
    "print('All features: train shape {}, test shape {}'.format(train_x.shape, test_x.shape))\n",
    "print(len(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "[0]\tvalidation_0-auc:0.808866\n",
      "Will train until validation_0-auc hasn't improved in 300 rounds.\n",
      "[100]\tvalidation_0-auc:0.889244\n",
      "[200]\tvalidation_0-auc:0.89408\n",
      "[300]\tvalidation_0-auc:0.895997\n",
      "[400]\tvalidation_0-auc:0.896953\n",
      "[500]\tvalidation_0-auc:0.897522\n",
      "[600]\tvalidation_0-auc:0.897778\n",
      "[700]\tvalidation_0-auc:0.89799\n",
      "[800]\tvalidation_0-auc:0.898137\n",
      "[900]\tvalidation_0-auc:0.898193\n",
      "[1000]\tvalidation_0-auc:0.898212\n",
      "[1100]\tvalidation_0-auc:0.898234\n",
      "[1200]\tvalidation_0-auc:0.898238\n",
      "[1300]\tvalidation_0-auc:0.898224\n",
      "[1400]\tvalidation_0-auc:0.898172\n",
      "[1500]\tvalidation_0-auc:0.898144\n",
      "Stopping. Best iteration:\n",
      "[1245]\tvalidation_0-auc:0.898258\n",
      "\n",
      "fold 1 round 1245 : score: 0.898258 | mean score 0.898258\n",
      "******************************\n",
      "[0]\tvalidation_0-auc:0.808905\n",
      "Will train until validation_0-auc hasn't improved in 300 rounds.\n",
      "[100]\tvalidation_0-auc:0.888921\n",
      "[200]\tvalidation_0-auc:0.894238\n",
      "[300]\tvalidation_0-auc:0.896161\n",
      "[400]\tvalidation_0-auc:0.89701\n",
      "[500]\tvalidation_0-auc:0.897552\n",
      "[600]\tvalidation_0-auc:0.897932\n",
      "[700]\tvalidation_0-auc:0.89817\n",
      "[800]\tvalidation_0-auc:0.898316\n",
      "[900]\tvalidation_0-auc:0.898376\n",
      "[1000]\tvalidation_0-auc:0.898442\n",
      "[1100]\tvalidation_0-auc:0.898452\n",
      "[1200]\tvalidation_0-auc:0.898437\n",
      "[1300]\tvalidation_0-auc:0.898529\n",
      "[1400]\tvalidation_0-auc:0.898532\n",
      "[1500]\tvalidation_0-auc:0.898508\n",
      "[1600]\tvalidation_0-auc:0.898496\n",
      "[1700]\tvalidation_0-auc:0.898475\n",
      "Stopping. Best iteration:\n",
      "[1425]\tvalidation_0-auc:0.898545\n",
      "\n",
      "fold 2 round 1425 : score: 0.898545 | mean score 0.898402\n",
      "******************************\n",
      "[0]\tvalidation_0-auc:0.810346\n",
      "Will train until validation_0-auc hasn't improved in 300 rounds.\n",
      "[100]\tvalidation_0-auc:0.889007\n",
      "[200]\tvalidation_0-auc:0.894046\n",
      "[300]\tvalidation_0-auc:0.895905\n",
      "[400]\tvalidation_0-auc:0.896836\n",
      "[500]\tvalidation_0-auc:0.897347\n",
      "[600]\tvalidation_0-auc:0.897683\n",
      "[700]\tvalidation_0-auc:0.897871\n",
      "[800]\tvalidation_0-auc:0.898009\n",
      "[900]\tvalidation_0-auc:0.898163\n",
      "[1000]\tvalidation_0-auc:0.898241\n",
      "[1100]\tvalidation_0-auc:0.898207\n",
      "[1200]\tvalidation_0-auc:0.898258\n",
      "[1300]\tvalidation_0-auc:0.898254\n",
      "[1400]\tvalidation_0-auc:0.898239\n",
      "[1500]\tvalidation_0-auc:0.898245\n",
      "[1600]\tvalidation_0-auc:0.898211\n",
      "Stopping. Best iteration:\n",
      "[1323]\tvalidation_0-auc:0.898268\n",
      "\n",
      "fold 3 round 1323 : score: 0.898268 | mean score 0.898357\n",
      "******************************\n",
      "[0]\tvalidation_0-auc:0.809638\n",
      "Will train until validation_0-auc hasn't improved in 300 rounds.\n",
      "[100]\tvalidation_0-auc:0.888812\n",
      "[200]\tvalidation_0-auc:0.894126\n",
      "[300]\tvalidation_0-auc:0.895938\n",
      "[400]\tvalidation_0-auc:0.896899\n",
      "[500]\tvalidation_0-auc:0.897464\n",
      "[600]\tvalidation_0-auc:0.897802\n",
      "[700]\tvalidation_0-auc:0.897985\n",
      "[800]\tvalidation_0-auc:0.898063\n",
      "[900]\tvalidation_0-auc:0.898124\n",
      "[1000]\tvalidation_0-auc:0.898175\n",
      "[1100]\tvalidation_0-auc:0.898212\n",
      "[1200]\tvalidation_0-auc:0.898253\n",
      "[1300]\tvalidation_0-auc:0.898268\n",
      "[1400]\tvalidation_0-auc:0.898251\n",
      "[1500]\tvalidation_0-auc:0.898223\n",
      "Stopping. Best iteration:\n",
      "[1272]\tvalidation_0-auc:0.898294\n",
      "\n",
      "fold 4 round 1272 : score: 0.898294 | mean score 0.898341\n",
      "******************************\n",
      "[0]\tvalidation_0-auc:0.810321\n",
      "Will train until validation_0-auc hasn't improved in 300 rounds.\n",
      "[100]\tvalidation_0-auc:0.889507\n",
      "[200]\tvalidation_0-auc:0.894585\n",
      "[300]\tvalidation_0-auc:0.89655\n",
      "[400]\tvalidation_0-auc:0.897462\n",
      "[500]\tvalidation_0-auc:0.897979\n",
      "[600]\tvalidation_0-auc:0.898283\n",
      "[700]\tvalidation_0-auc:0.898475\n",
      "[800]\tvalidation_0-auc:0.898628\n",
      "[900]\tvalidation_0-auc:0.898743\n",
      "[1000]\tvalidation_0-auc:0.898808\n",
      "[1100]\tvalidation_0-auc:0.898808\n",
      "[1200]\tvalidation_0-auc:0.898857\n",
      "[1300]\tvalidation_0-auc:0.898849\n",
      "[1400]\tvalidation_0-auc:0.898844\n",
      "[1500]\tvalidation_0-auc:0.898831\n",
      "[1600]\tvalidation_0-auc:0.898806\n",
      "Stopping. Best iteration:\n",
      "[1320]\tvalidation_0-auc:0.898872\n",
      "\n",
      "fold 5 round 1320 : score: 0.898872 | mean score 0.898447\n",
      "Wall time: 8488 s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "preds = np.zeros((test_x.shape[0], 2))\n",
    "scores = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for index, (tr_idx, va_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "    print('*' * 30)\n",
    "    X_train, y_train, X_valid, y_valid = train_x.iloc[tr_idx], train_y.iloc[tr_idx], train_x.iloc[va_idx], train_y.iloc[va_idx]\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "                                n_estimators=50000,\n",
    "                                max_depth=12,\n",
    "                                learning_rate=0.1,\n",
    "                                reg_lambda=10,\n",
    "                                subsample=0.8,\n",
    "                                colsample_bytree=0.8,\n",
    "                                missing=np.nan,\n",
    "                                random_state=42,\n",
    "                                tree_method='gpu_hist'  \n",
    "                            )\n",
    "    xgb_model.fit(X_train, y_train, eval_set = [(X_valid, y_valid)], eval_metric='auc', early_stopping_rounds=300, verbose=100)\n",
    "\n",
    "    score = xgb_model.best_score\n",
    "    scores.append(score)\n",
    "    print('fold %d round %d : score: %.6f | mean score %.6f' % (index+1, xgb_model.best_iteration, score,np.mean(scores))) \n",
    "    pred = xgb_model.predict_proba(test_x)\n",
    "    preds += pred  #mean score 0.8970\n",
    "    np.save('./out/xgb_preds_{}.npy'.format(index+1), pred)\n",
    "\n",
    "    pickle.dump(xgb_model, open('./models/main_xgb_f%d.pkl' % index, \"wb\"))\n",
    "\n",
    "    del xgb_model\n",
    "    del X_train, y_train, X_valid, y_valid\n",
    "    gc.collect()\n",
    "    \n",
    "toc = time.time()\n",
    "print(\"Wall time: %d s\" % (toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "invite_info_evaluate = pd.read_table('../data/data_set_0926/invite_info_evaluate_2_0926.txt',header=None)\n",
    "invite_info_evaluate.columns =  ['问题ID','用户ID','邀请创建时间']\n",
    "result = invite_info_evaluate[['问题ID','用户ID','邀请创建时间']]\n",
    "result['result'] = preds[:, 1] / 5\n",
    "result.to_csv('./out/result_xgb_nouser.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
