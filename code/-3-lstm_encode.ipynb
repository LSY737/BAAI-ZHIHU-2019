{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, CuDNNLSTM, Bidirectional, Embedding, CuDNNGRU, Conv1D, MaxPooling1D\n",
    "from keras.layers import Flatten, PReLU, Dropout, BatchNormalization, SpatialDropout1D, concatenate\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer \n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/data_set_0926/'\n",
    "FEAT_PATH = './features/'\n",
    "WEIGHT_PATH = './weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "invite_info = pd.read_table(os.path.join(DATA_PATH 'invite_info_0926.txt'), header=None)\n",
    "invite_info.columns = ['问题ID','用户ID','邀请创建时间','邀请是否被回答']\n",
    "\n",
    "invite_info_evaluate_A = pd.read_table(os.path.join(DATA_PATH, 'invite_info_evaluate_1_0926.txt'), header=None)\n",
    "invite_info_evaluate_A.columns =  ['问题ID','用户ID','邀请创建时间']\n",
    "\n",
    "invite_info_evaluate_B = pd.read_table(os.path.join(DATA_PATH, 'invite_info_evaluate_2_0926.txt'), header=None)\n",
    "invite_info_evaluate_B.columns =  ['问题ID','用户ID','邀请创建时间']\n",
    "\n",
    "question_info = pd.read_table(os.path.join(DATA_PATH, 'question_info_0926.txt', header=None)\n",
    "question_info.columns = ['问题ID',  '问题创建时间' , '问题标题的单字编码序列' , '问题标题的切词编码序列' , '问题描述的单字编码序列',  '问题描述的词编码序列' , '问题绑定的话题ID']\n",
    "\n",
    "member_info = pd.read_table(os.path.join(DATA_PATH, 'member_info_0926.txt'), header=None)\n",
    "member_info.columns = ['用户ID','性别','创作关键词的编码序列','创作数量等级','创作热度等级','注册类型','注册平台','访问频率','用户二分类特征A','用户二分类特征B','用户二分类特征C','用户二分类特征D','用户二分类特征E','用户分类特征A','用户分类特征B','用户分类特征C','用户分类特征D','用户分类特征E','用户的盐值分数','用户关注的话题','用户感兴趣的话题']\n",
    "\n",
    "tmp = member_info['用户感兴趣的话题'].apply(lambda x: re.split('[,:]',x))\n",
    "member_info['用户感兴趣的话题_T'] = tmp.apply(lambda x : ','.join(x[::2]))\n",
    "member_info['用户感兴趣的话题_score'] = tmp.apply(lambda x : ','.join(x[1::2]))\n",
    "                              \n",
    "oversample = False\n",
    "\n",
    "if oversample:\n",
    "    data = pd.concat([invite_info, invite_info_evaluate_B, invite_info_evaluate_A], axis=0)\n",
    "else:\n",
    "    data = pd.concat([invite_info, invite_info_evaluate_B], axis=0)\n",
    "                              \n",
    "data = data.merge(question_info, on='问题ID', how='left').merge(member_info, on='用户ID', how='left')\n",
    "                              \n",
    "del question_info ,member_info, tmp, invite_info_evaluate_A, invite_info_evaluate_B\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 44s, sys: 30.9 s, total: 8min 14s\n",
      "Wall time: 8min 21s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "data_new = pd.DataFrame()\n",
    "data_new['author_id'] = data['用户ID']\n",
    "data_new['question_id'] = data['问题ID']\n",
    "data_new['label'] = data['邀请是否被回答']\n",
    "data_new['title_w_series'] = data['问题标题的切词编码序列'].apply(lambda x: [int(num[1:]) for num in x.split(',')])\n",
    "data_new['desc_w_series'] = data['问题描述的词编码序列'].apply(lambda x:[int(num[1:]) for num in x.split(',')])\n",
    "data_new['topic_attent'] = data['用户关注的话题'].apply(lambda x:[int(num[1:]) for num in x.split(',')])\n",
    "data_new['topic_interest'] = data['用户感兴趣的话题_T'].apply(lambda x:[int(num[1:]) for num in x.split(',')])\n",
    "data_new['topic'] = data['问题绑定的话题ID'].apply(lambda x:[int(num[1:]) for num in x.split(',')])\n",
    "del data\n",
    "gc.collect()\n",
    "data = data_new\n",
    "print(\"Used time: %d s\" % (time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word = pd.read_table(os.path.join(DATA_PATH, 'word_vectors_64d.txt'), header=None)\n",
    "word.columns = ['id','embed']\n",
    "word['id'] = word['id'].apply(lambda x: int(x[1:]))\n",
    "word['embed'] = word['embed'].apply(lambda x: [float(num) for num in x.split(' ')])\n",
    "\n",
    "topic = pd.read_table(os.path.join(DATA_PATH, 'topic_vectors_64d.txt'), header=None)\n",
    "topic.columns = ['id','embed']\n",
    "topic['id'] = topic['id'].apply(lambda x: int(x[1:]))\n",
    "topic['embed'] = topic['embed'].apply(lambda x: [float(num) for num in x.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_doc_size = 128\n",
    "seq_feat = ['topic_attent', 'topic_interest', 'title_w_series', 'desc_w_series', 'topic']\n",
    "\n",
    "for f in seq_feat:\n",
    "    if data[f].apply(len).max() >  max_doc_size:\n",
    "        data[f] = data[f].apply(lambda x: x[:max_doc_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('topic_attent', 100001, 100),\n",
       " ('topic_interest', 100001, 10),\n",
       " ('title_w_series', 1762830, 38),\n",
       " ('desc_w_series', 1762830, 128),\n",
       " ('topic', 100001, 13)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name, in_dim, seq_length\n",
    "seq_embed_cnt = [(f, (len(topic) if 'topic' in f else len(word)) + 1, data[f].apply(len).max()) for f in seq_feat]\n",
    "print(seq_embed_cnt)\n",
    "\n",
    "# seq embed weight \n",
    "embed_weights = {'word': np.array([[0] * 64] + [list(v) for v in word['embed'].values]), \n",
    "                'topic': np.array([[0] * 64] + [list(v) for v in topic['embed'].values])}\n",
    "\n",
    "del word, topic\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9489162, 8)\n",
      "(1141718, 8)\n"
     ]
    }
   ],
   "source": [
    "train = data[:len(invite_info)]\n",
    "test = data[len(invite_info):]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "del data,data_new, invite_info\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {key:array}\n",
    "train = train.to_dict(orient='list')\n",
    "test = test.to_dict(orient='list')\n",
    "for k in train.keys():\n",
    "    train[k] = np.array(train[k])\n",
    "for k in test.keys():\n",
    "    test[k] = np.array(test[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_attent\n",
      "topic_interest\n",
      "title_w_series\n",
      "desc_w_series\n",
      "topic\n",
      "CPU times: user 12min 2s, sys: 34.4 s, total: 12min 37s\n",
      "Wall time: 12min 35s\n"
     ]
    }
   ],
   "source": [
    "## padding\n",
    "for f, _, maxlen in seq_embed_cnt:\n",
    "    print(f)\n",
    "    train[f] = pad_sequences(train[f], maxlen=maxlen)\n",
    "    test[f] = pad_sequences(test[f], maxlen=maxlen)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "class DictWrapper(collections.Sequence):\n",
    "    def __init__(self, d):\n",
    "        self.d = d\n",
    "    def __len__(self):\n",
    "        return len(self.d[list(self.d.keys())[0]])\n",
    "    def __getitem__(self, position):\n",
    "        return DictWrapper(dict((k, v[position]) for k, v in self.d.items()))\n",
    "    \n",
    "train = DictWrapper(train)\n",
    "test = DictWrapper(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Position_Embedding(Layer): \n",
    "    def __init__(self, size=None, mode='sum', **kwargs):        \n",
    "        self.size = size         \n",
    "        self.mode = mode       \n",
    "        super(Position_Embedding, self).__init__(**kwargs) \n",
    "\n",
    "    def call(self, x): \n",
    "        if (self.size == None) or (self.mode == 'sum'):            \n",
    "            self.size = int(x.shape[-1])        \n",
    "            batch_size, seq_len = K.shape(x)[0], K.shape(x)[1]        \n",
    "            position_j = 1. / K.pow(10000., \\\n",
    "                2 * K.arange(self.size / 2, dtype='float32') / self.size)        \n",
    "            position_j = K.expand_dims(position_j, 0)        \n",
    "            position_i = K.cumsum(K.ones_like(x[:, :, 0]), 1)-1     \n",
    "            position_i = K.expand_dims(position_i, 2)        \n",
    "            position_ij = K.dot(position_i, position_j)        \n",
    "            position_ij = K.concatenate([K.cos(position_ij), K.sin(position_ij)], 2) \n",
    "            if self.mode == 'sum': \n",
    "                return position_ij + x \n",
    "            elif self.mode == 'concat': \n",
    "                return K.concatenate([position_ij, x], 2) \n",
    "\n",
    "    def compute_output_shape(self, input_shape): \n",
    "        if self.mode == 'sum': \n",
    "            return input_shape \n",
    "        elif self.mode == 'concat': \n",
    "            return (input_shape[0], input_shape[1], input_shape[2]+self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_LSTM(seq_embed_cnt, seq_embed_size=64, embed_weights=None):\n",
    "    \n",
    "    # sequence embedding\n",
    "    inp_seq_embed = []\n",
    "    out_seq_embed = []\n",
    "    for feat_name, inp_embed_dim, seq_length in seq_embed_cnt:\n",
    "        inp = Input(shape=(seq_length,))\n",
    "        inp_seq_embed.append(inp)\n",
    "        weights = (embed_weights['topic'] if 'topic' in feat_name else embed_weights['word'])\n",
    "        x = Embedding(inp_embed_dim, seq_embed_size, weights=[weights], trainable=False)(inp)\n",
    "        x = Position_Embedding()(x)\n",
    "        x = SpatialDropout1D(0.1)(x)\n",
    "        x = Bidirectional(CuDNNGRU(32, return_sequences=True))(x)\n",
    "        atten_1 = Attention(seq_length)(x)\n",
    "        convs = []\n",
    "        filter_sizes = [2, 4, 6, 10]\n",
    "        for fsz in filter_sizes:\n",
    "            l_conv = Conv1D(filters=seq_length, kernel_size=fsz, activation='relu')(x)\n",
    "            l_pool = MaxPooling1D((seq_length - fsz + 1,))(l_conv)\n",
    "            l_pool = Flatten()(l_pool)\n",
    "            convs.append(l_pool)\n",
    "        text_cnn = concatenate(convs, axis=1)\n",
    "        out_seq_embed.extend([atten_1, text_cnn])\n",
    "     \n",
    "    # concat\n",
    "    conc = concatenate(out_seq_embed)\n",
    "    conc = Dense(256)(conc)\n",
    "    conc = BatchNormalization()(conc)\n",
    "    conc = PReLU()(conc)\n",
    "    conc = Dropout(0.2)(conc)\n",
    "    conc = Dense(128)(conc)\n",
    "    conc = BatchNormalization()(conc)\n",
    "    out = Dense(1, activation=\"sigmoid\")(conc)\n",
    "    model = Model(inputs=inp_seq_embed, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSequence(Sequence):\n",
    "    \n",
    "    def __init__(self, x, y, seq_embed_feat, batch_size=128):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.seq_embed_feat = seq_embed_feat\n",
    "        self.batch_size = batch_size\n",
    "        self.x_seq_embed = [x.d[f] for f in seq_embed_feat] \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_idx = np.arange(idx * self.batch_size, min((idx + 1) * self.batch_size, len(self.x)))\n",
    "        batch_x = [xf[batch_idx] for xf in self.x_seq_embed]\n",
    "        batch_y = self.y[batch_idx]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, trn_x, y_trn,val_x, y_val, batch_size=128, save_name='weight.h5'):\n",
    "        self.trn_generator = DataSequence(trn_x, y_trn, seq_feat, batch_size=batch_size)\n",
    "        self.val_generator = DataSequence(val_x, y_val, seq_feat, batch_size=batch_size)\n",
    "        self.y_trn = y_trn\n",
    "        self.y_val = y_val\n",
    "        self.save_name = save_name\n",
    "        self.best_score = 0.5\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # eval train\n",
    "        y_pred = self.model.predict_generator(self.trn_generator, \n",
    "                                              max_queue_size=10, \n",
    "                                              workers=1, \n",
    "                                              use_multiprocessing=False, \n",
    "                                              verbose=0)\n",
    "        roc = roc_auc_score(self.y_trn, y_pred)\n",
    "        # eval valid\n",
    "        y_pred_val = self.model.predict_generator(self.val_generator, \n",
    "                                              max_queue_size=10, \n",
    "                                              workers=1, \n",
    "                                              use_multiprocessing=False, \n",
    "                                              verbose=0)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "\n",
    "        if roc_val > self.best_score:\n",
    "            self.best_score = roc_val\n",
    "            self.model.save_weights(os.path.join(WEIGHT_PATH, self.save_name))\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Epoch 1/15\n",
      "7414/7414 [==============================] - 1423s 192ms/step - loss: 0.4474 - val_loss: 0.4429\n",
      "roc-auc: 0.6751 - roc-auc_val: 0.6706                                                                                                    \n",
      "Epoch 2/15\n",
      "7414/7414 [==============================] - 1412s 190ms/step - loss: 0.4394 - val_loss: 0.4362\n",
      "roc-auc: 0.6878 - roc-auc_val: 0.6794                                                                                                    \n",
      "Epoch 3/15\n",
      "7414/7414 [==============================] - 1405s 190ms/step - loss: 0.4357 - val_loss: 0.4337\n",
      "roc-auc: 0.6977 - roc-auc_val: 0.6864                                                                                                    \n",
      "Epoch 4/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4327 - val_loss: 0.4360\n",
      "roc-auc: 0.7089 - roc-auc_val: 0.6931                                                                                                    \n",
      "Epoch 5/15\n",
      "7414/7414 [==============================] - 1404s 189ms/step - loss: 0.4302 - val_loss: 0.4364\n",
      "roc-auc: 0.7096 - roc-auc_val: 0.6918                                                                                                    \n",
      "Epoch 6/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4283 - val_loss: 0.4342\n",
      "roc-auc: 0.7165 - roc-auc_val: 0.6976                                                                                                    \n",
      "Epoch 7/15\n",
      "7414/7414 [==============================] - 1405s 190ms/step - loss: 0.4266 - val_loss: 0.4273\n",
      "roc-auc: 0.7245 - roc-auc_val: 0.7023                                                                                                    \n",
      "Epoch 8/15\n",
      "7414/7414 [==============================] - 1404s 189ms/step - loss: 0.4252 - val_loss: 0.4259\n",
      "roc-auc: 0.73 - roc-auc_val: 0.7052                                                                                                    \n",
      "Epoch 9/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4237 - val_loss: 0.4288\n",
      "roc-auc: 0.7333 - roc-auc_val: 0.7065                                                                                                    \n",
      "Epoch 10/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4226 - val_loss: 0.4245\n",
      "roc-auc: 0.7373 - roc-auc_val: 0.7081                                                                                                    \n",
      "Epoch 11/15\n",
      "7414/7414 [==============================] - 1405s 190ms/step - loss: 0.4215 - val_loss: 0.4246\n",
      "roc-auc: 0.739 - roc-auc_val: 0.7082                                                                                                    \n",
      "Epoch 12/15\n",
      "7414/7414 [==============================] - 1405s 190ms/step - loss: 0.4205 - val_loss: 0.4247\n",
      "roc-auc: 0.7428 - roc-auc_val: 0.71                                                                                                    \n",
      "Epoch 13/15\n",
      "7414/7414 [==============================] - 1405s 190ms/step - loss: 0.4196 - val_loss: 0.4286\n",
      "roc-auc: 0.7426 - roc-auc_val: 0.7092                                                                                                    \n",
      "Epoch 14/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4186 - val_loss: 0.4287\n",
      "roc-auc: 0.7438 - roc-auc_val: 0.7098                                                                                                    \n",
      "Epoch 15/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4178 - val_loss: 0.4278\n",
      "roc-auc: 0.7483 - roc-auc_val: 0.7118                                                                                                    \n",
      "******************************\n",
      "Epoch 1/15\n",
      "7414/7414 [==============================] - 1418s 191ms/step - loss: 0.4473 - val_loss: 0.4448\n",
      "roc-auc: 0.6751 - roc-auc_val: 0.6703                                                                                                    \n",
      "Epoch 2/15\n",
      "7414/7414 [==============================] - 1408s 190ms/step - loss: 0.4392 - val_loss: 0.4463\n",
      "roc-auc: 0.6861 - roc-auc_val: 0.6776                                                                                                    \n",
      "Epoch 3/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4356 - val_loss: 0.4329\n",
      "roc-auc: 0.7009 - roc-auc_val: 0.6885                                                                                                    \n",
      "Epoch 4/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4328 - val_loss: 0.4330\n",
      "roc-auc: 0.7087 - roc-auc_val: 0.6937                                                                                                    \n",
      "Epoch 5/15\n",
      "7414/7414 [==============================] - 1407s 190ms/step - loss: 0.4303 - val_loss: 0.4311\n",
      "roc-auc: 0.7129 - roc-auc_val: 0.6945                                                                                                    \n",
      "Epoch 6/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4284 - val_loss: 0.4409\n",
      "roc-auc: 0.72 - roc-auc_val: 0.6995                                                                                                    \n",
      "Epoch 7/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4268 - val_loss: 0.4342\n",
      "roc-auc: 0.7219 - roc-auc_val: 0.7002                                                                                                    \n",
      "Epoch 8/15\n",
      "7414/7414 [==============================] - 1407s 190ms/step - loss: 0.4253 - val_loss: 0.4324\n",
      "roc-auc: 0.7269 - roc-auc_val: 0.7033                                                                                                    \n",
      "Epoch 9/15\n",
      "7414/7414 [==============================] - 1408s 190ms/step - loss: 0.4242 - val_loss: 0.4287\n",
      "roc-auc: 0.7299 - roc-auc_val: 0.704                                                                                                    \n",
      "Epoch 10/15\n",
      "7414/7414 [==============================] - 1402s 189ms/step - loss: 0.4228 - val_loss: 0.4263\n",
      "roc-auc: 0.7337 - roc-auc_val: 0.7066                                                                                                    \n",
      "Epoch 11/15\n",
      "7414/7414 [==============================] - 1405s 190ms/step - loss: 0.4218 - val_loss: 0.4256\n",
      "roc-auc: 0.7376 - roc-auc_val: 0.7072                                                                                                    \n",
      "Epoch 12/15\n",
      "7414/7414 [==============================] - 1412s 190ms/step - loss: 0.4207 - val_loss: 0.4257\n",
      "roc-auc: 0.7399 - roc-auc_val: 0.7085                                                                                                    \n",
      "Epoch 13/15\n",
      "7414/7414 [==============================] - 1410s 190ms/step - loss: 0.4198 - val_loss: 0.4260\n",
      "roc-auc: 0.7428 - roc-auc_val: 0.7104                                                                                                    \n",
      "Epoch 14/15\n",
      "7414/7414 [==============================] - 1410s 190ms/step - loss: 0.4189 - val_loss: 0.4267\n",
      "roc-auc: 0.7418 - roc-auc_val: 0.7082                                                                                                    \n",
      "Epoch 15/15\n",
      "7414/7414 [==============================] - 1412s 190ms/step - loss: 0.4181 - val_loss: 0.4247\n",
      "roc-auc: 0.7482 - roc-auc_val: 0.7123                                                                                                    \n",
      "******************************\n",
      "Epoch 1/15\n",
      "7414/7414 [==============================] - 1422s 192ms/step - loss: 0.4473 - val_loss: 0.4405\n",
      "roc-auc: 0.6748 - roc-auc_val: 0.6697                                                                                                    \n",
      "Epoch 2/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4392 - val_loss: 0.4443\n",
      "roc-auc: 0.6849 - roc-auc_val: 0.6765                                                                                                    \n",
      "Epoch 3/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4356 - val_loss: 0.4374\n",
      "roc-auc: 0.7012 - roc-auc_val: 0.6881                                                                                                    \n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7414/7414 [==============================] - 1407s 190ms/step - loss: 0.4325 - val_loss: 0.4315\n",
      "roc-auc: 0.7108 - roc-auc_val: 0.6943                                                                                                    \n",
      "Epoch 5/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4301 - val_loss: 0.4289\n",
      "roc-auc: 0.7167 - roc-auc_val: 0.6979                                                                                                    \n",
      "Epoch 6/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4281 - val_loss: 0.4284\n",
      "roc-auc: 0.7212 - roc-auc_val: 0.6999                                                                                                    \n",
      "Epoch 7/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4263 - val_loss: 0.4299\n",
      "roc-auc: 0.7275 - roc-auc_val: 0.7028                                                                                                    \n",
      "Epoch 8/15\n",
      "7414/7414 [==============================] - 1404s 189ms/step - loss: 0.4248 - val_loss: 0.4276\n",
      "roc-auc: 0.7299 - roc-auc_val: 0.7038                                                                                                    \n",
      "Epoch 9/15\n",
      "7414/7414 [==============================] - 1404s 189ms/step - loss: 0.4235 - val_loss: 0.4282\n",
      "roc-auc: 0.7337 - roc-auc_val: 0.7067                                                                                                    \n",
      "Epoch 10/15\n",
      "7414/7414 [==============================] - 1409s 190ms/step - loss: 0.4222 - val_loss: 0.4262\n",
      "roc-auc: 0.7373 - roc-auc_val: 0.7082                                                                                                    \n",
      "Epoch 11/15\n",
      "7414/7414 [==============================] - 1404s 189ms/step - loss: 0.4212 - val_loss: 0.4248\n",
      "roc-auc: 0.7412 - roc-auc_val: 0.7086                                                                                                    \n",
      "Epoch 12/15\n",
      "7414/7414 [==============================] - 1401s 189ms/step - loss: 0.4201 - val_loss: 0.4269\n",
      "roc-auc: 0.7432 - roc-auc_val: 0.7104                                                                                                    \n",
      "Epoch 13/15\n",
      "7414/7414 [==============================] - 1405s 190ms/step - loss: 0.4191 - val_loss: 0.4244\n",
      "roc-auc: 0.747 - roc-auc_val: 0.7105                                                                                                    \n",
      "Epoch 14/15\n",
      "7414/7414 [==============================] - 1404s 189ms/step - loss: 0.4183 - val_loss: 0.4236\n",
      "roc-auc: 0.7474 - roc-auc_val: 0.7114                                                                                                    \n",
      "Epoch 15/15\n",
      "7414/7414 [==============================] - 1415s 191ms/step - loss: 0.4175 - val_loss: 0.4238\n",
      "roc-auc: 0.7498 - roc-auc_val: 0.7119                                                                                                    \n",
      "******************************\n",
      "Epoch 1/15\n",
      "7414/7414 [==============================] - 1428s 193ms/step - loss: 0.4472 - val_loss: 0.4427\n",
      "roc-auc: 0.6664 - roc-auc_val: 0.6611                                                                                                    \n",
      "Epoch 2/15\n",
      "7414/7414 [==============================] - 1414s 191ms/step - loss: 0.4393 - val_loss: 0.4425\n",
      "roc-auc: 0.6887 - roc-auc_val: 0.6802                                                                                                    \n",
      "Epoch 3/15\n",
      "7414/7414 [==============================] - 1428s 193ms/step - loss: 0.4358 - val_loss: 0.4373\n",
      "roc-auc: 0.6997 - roc-auc_val: 0.6874                                                                                                    \n",
      "Epoch 4/15\n",
      "7414/7414 [==============================] - 1421s 192ms/step - loss: 0.4328 - val_loss: 0.4392\n",
      "roc-auc: 0.7088 - roc-auc_val: 0.6924                                                                                                    \n",
      "Epoch 5/15\n",
      "7414/7414 [==============================] - 1411s 190ms/step - loss: 0.4304 - val_loss: 0.4302\n",
      "roc-auc: 0.7153 - roc-auc_val: 0.6962                                                                                                    \n",
      "Epoch 6/15\n",
      "7414/7414 [==============================] - 1397s 188ms/step - loss: 0.4284 - val_loss: 0.4285\n",
      "roc-auc: 0.7182 - roc-auc_val: 0.6981                                                                                                    \n",
      "Epoch 7/15\n",
      "7414/7414 [==============================] - 1403s 189ms/step - loss: 0.4267 - val_loss: 0.4338\n",
      "roc-auc: 0.7217 - roc-auc_val: 0.7                                                                                                    \n",
      "Epoch 8/15\n",
      "7414/7414 [==============================] - 1403s 189ms/step - loss: 0.4253 - val_loss: 0.4286\n",
      "roc-auc: 0.7282 - roc-auc_val: 0.703                                                                                                    \n",
      "Epoch 9/15\n",
      "7414/7414 [==============================] - 1401s 189ms/step - loss: 0.4239 - val_loss: 0.4341\n",
      "roc-auc: 0.7302 - roc-auc_val: 0.705                                                                                                    \n",
      "Epoch 10/15\n",
      "7414/7414 [==============================] - 1404s 189ms/step - loss: 0.4227 - val_loss: 0.4298\n",
      "roc-auc: 0.7313 - roc-auc_val: 0.7026                                                                                                    \n",
      "Epoch 11/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4215 - val_loss: 0.4272\n",
      "roc-auc: 0.7381 - roc-auc_val: 0.7077                                                                                                    \n",
      "Epoch 12/15\n",
      "7414/7414 [==============================] - 1401s 189ms/step - loss: 0.4205 - val_loss: 0.4319\n",
      "roc-auc: 0.7419 - roc-auc_val: 0.709                                                                                                    \n",
      "Epoch 13/15\n",
      "7414/7414 [==============================] - 1401s 189ms/step - loss: 0.4195 - val_loss: 0.4254\n",
      "roc-auc: 0.745 - roc-auc_val: 0.7089                                                                                                    \n",
      "Epoch 14/15\n",
      "7414/7414 [==============================] - 1404s 189ms/step - loss: 0.4187 - val_loss: 0.4242\n",
      "roc-auc: 0.7468 - roc-auc_val: 0.712                                                                                                    \n",
      "Epoch 15/15\n",
      "7414/7414 [==============================] - 1400s 189ms/step - loss: 0.4178 - val_loss: 0.4241\n",
      "roc-auc: 0.7484 - roc-auc_val: 0.7124                                                                                                    \n",
      "******************************\n",
      "Epoch 1/15\n",
      "7414/7414 [==============================] - 1414s 191ms/step - loss: 0.4471 - val_loss: 0.4391\n",
      "roc-auc: 0.6769 - roc-auc_val: 0.6715                                                                                                    \n",
      "Epoch 2/15\n",
      "7414/7414 [==============================] - 1410s 190ms/step - loss: 0.4394 - val_loss: 0.4356\n",
      "roc-auc: 0.6908 - roc-auc_val: 0.6811                                                                                                    \n",
      "Epoch 3/15\n",
      "7414/7414 [==============================] - 1408s 190ms/step - loss: 0.4358 - val_loss: 0.4348\n",
      "roc-auc: 0.6999 - roc-auc_val: 0.6873                                                                                                    \n",
      "Epoch 4/15\n",
      "7414/7414 [==============================] - 1407s 190ms/step - loss: 0.4328 - val_loss: 0.4310\n",
      "roc-auc: 0.7088 - roc-auc_val: 0.6928                                                                                                    \n",
      "Epoch 5/15\n",
      "7414/7414 [==============================] - 1407s 190ms/step - loss: 0.4304 - val_loss: 0.4297\n",
      "roc-auc: 0.7157 - roc-auc_val: 0.697                                                                                                    \n",
      "Epoch 6/15\n",
      "7414/7414 [==============================] - 1397s 188ms/step - loss: 0.4282 - val_loss: 0.4309\n",
      "roc-auc: 0.7176 - roc-auc_val: 0.6981                                                                                                    \n",
      "Epoch 7/15\n",
      "7414/7414 [==============================] - 1407s 190ms/step - loss: 0.4266 - val_loss: 0.4272\n",
      "roc-auc: 0.7269 - roc-auc_val: 0.7033                                                                                                    \n",
      "Epoch 8/15\n",
      "7414/7414 [==============================] - 1407s 190ms/step - loss: 0.4250 - val_loss: 0.4289\n",
      "roc-auc: 0.731 - roc-auc_val: 0.7054                                                                                                    \n",
      "Epoch 9/15\n",
      "7414/7414 [==============================] - 1406s 190ms/step - loss: 0.4236 - val_loss: 0.4274\n",
      "roc-auc: 0.7333 - roc-auc_val: 0.7057                                                                                                    \n",
      "Epoch 10/15\n",
      "7414/7414 [==============================] - 1405s 189ms/step - loss: 0.4224 - val_loss: 0.4254\n",
      "roc-auc: 0.7374 - roc-auc_val: 0.7084                                                                                                    \n",
      "Epoch 11/15\n",
      "7414/7414 [==============================] - 1408s 190ms/step - loss: 0.4213 - val_loss: 0.4250\n",
      "roc-auc: 0.7418 - roc-auc_val: 0.7096                                                                                                    \n",
      "Epoch 12/15\n",
      "7414/7414 [==============================] - 1408s 190ms/step - loss: 0.4203 - val_loss: 0.4254\n",
      "roc-auc: 0.744 - roc-auc_val: 0.711                                                                                                    \n",
      "Epoch 13/15\n",
      "7414/7414 [==============================] - 1409s 190ms/step - loss: 0.4192 - val_loss: 0.4240\n",
      "roc-auc: 0.7453 - roc-auc_val: 0.7116                                                                                                    \n",
      "Epoch 14/15\n",
      "7414/7414 [==============================] - 1414s 191ms/step - loss: 0.4184 - val_loss: 0.4259\n",
      "roc-auc: 0.7462 - roc-auc_val: 0.7103                                                                                                    \n",
      "Epoch 15/15\n",
      "7414/7414 [==============================] - 1409s 190ms/step - loss: 0.4176 - val_loss: 0.4331\n",
      "roc-auc: 0.7444 - roc-auc_val: 0.708                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "train_x, train_y = train, train.d['label']\n",
    "\n",
    "for i, seeds in enumerate([42]):\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seeds)\n",
    "    for index, (tr_idx, va_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        print('*' * 30)\n",
    "        X_train, y_train, X_valid, y_valid = train_x[tr_idx], train_y[tr_idx], train_x[va_idx], train_y[va_idx]\n",
    "        trn_generator = DataSequence(X_train, y_train, seq_feat, batch_size=BATCH_SIZE)\n",
    "        val_generator = DataSequence(X_valid, y_valid, seq_feat, batch_size=BATCH_SIZE)\n",
    "        K.clear_session()\n",
    "        model = DNN_LSTM(seq_embed_cnt, seq_embed_size=64, embed_weights=embed_weights)\n",
    "        model.compile(loss ='binary_crossentropy', optimizer='Adam')  #logloss\n",
    "        history = model.fit_generator(generator=trn_generator,\n",
    "                                      validation_data=val_generator,\n",
    "                                      epochs=15, \n",
    "                                      verbose=1, \n",
    "                                      callbacks=[MetricsCallback(X_train, y_train,\n",
    "                                                   X_valid, y_valid, \n",
    "                                                   batch_size=BATCH_SIZE*4, \n",
    "                                                   save_name='lstm_fold_%d.h5' % index)],\n",
    "                                      max_queue_size=10, \n",
    "                                      workers=1, \n",
    "                                      use_multiprocessing=False)  #0.6660\n",
    "        \n",
    "        del X_train, y_train, X_valid, y_valid\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 0\n",
      "1854/1854 [==============================] - 121s 65ms/step\n",
      "1115/1115 [==============================] - 72s 64ms/step\n",
      "0.7117546495794349\n",
      "Predict Done.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 1\n",
      "1854/1854 [==============================] - 109s 59ms/step\n",
      "1115/1115 [==============================] - 65s 58ms/step\n",
      "0.7122995297749857\n",
      "Predict Done.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 2\n",
      "1854/1854 [==============================] - 109s 59ms/step\n",
      "1115/1115 [==============================] - 66s 59ms/step\n",
      "0.7119206606310954\n",
      "Predict Done.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 3\n",
      "1854/1854 [==============================] - 109s 59ms/step\n",
      "1115/1115 [==============================] - 64s 58ms/step\n",
      "0.7124045318508603\n",
      "Predict Done.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fold 4\n",
      "1854/1854 [==============================] - 109s 59ms/step\n",
      "1115/1115 [==============================] - 66s 59ms/step\n",
      "0.711623117109101\n",
      "Predict Done.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "test_x = test\n",
    "train_x, train_y = train, train.d['label']\n",
    "test_generator = DataSequence(test_x, np.zeros(len(test_x)), seq_feat, batch_size=BATCH_SIZE)\n",
    "\n",
    "stack_test = np.zeros((len(test_x), 1))\n",
    "stack_train = np.zeros((len(train_x), 1))\n",
    "\n",
    "for i, (tr_idx, va_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "\n",
    "    print('-'*100)\n",
    "    print('Fold %d' % i)\n",
    "    X_train, y_train, X_valid, y_valid = train_x[tr_idx], train_y[tr_idx], train_x[va_idx], train_y[va_idx]\n",
    "\n",
    "    K.clear_session()\n",
    "    model = DNN_LSTM(seq_embed_cnt, seq_embed_size=64, embed_weights=embed_weights)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',)\n",
    "\n",
    "    val_generator = DataSequence(X_valid, y_valid, seq_feat, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model.load_weights(os.path.join(WEIGHT_PATH, 'lstm_fold_%d.h5' % i))\n",
    "\n",
    "    stack_train[va_idx] = model.predict_generator(val_generator, verbose=1)\n",
    "    stack_test += model.predict_generator(test_generator, verbose=1) / 5\n",
    "    \n",
    "    print(roc_auc_score(y_valid, stack_train[va_idx]))\n",
    "    \n",
    "    del X_valid, y_valid\n",
    "    gc.collect()\n",
    "    print('Predict Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = np.vstack([stack_train, stack_test])\n",
    "df_stack = pd.DataFrame()\n",
    "df_stack['lstm_enc_feat'] = stack[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved, shape: (10630880, 1)\n"
     ]
    }
   ],
   "source": [
    "df_stack.to_pickle(os.path.join(FEAT_PATH, 'lstm_enc_feat.pickle'))\n",
    "print(\"Feature saved, shape:\",df_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
